<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="main.css?ver0.0.3">
    <script src="main.js"></script>
    <title>Patrick King's Portfolio</title>
</head>
<body>
    <nav>
        <div class="navbar">
            <button class='navButton' onclick="scrollToElement('aboutMe')">About Me</button>
            <button class='navButton' onclick="scrollToElement('projects')">Projects</button>
            <a href="https://github.com/pkingGMU?tab=repositories" class = "navButton" target="_blank">GitHub</a> 
            <a href="https://www.linkedin.com/in/patrick-king-152193184/" class = "navButton" target="_blank">LinkedIn</a> 
        </div>
    </nav>

    <main>
        <!--Introduction-->
        <section>
            <h1 class = 'aboutme' id="aboutMe">About Me</h1>
            <p>
                My name is Patrick King and I am currently a Kinesiology and Exercise Science major at George Mason University. 
                My passion for human movement and technology intertwine in my roles as an 
                Undergraduate Student Researcher and a Research Assistant. 
            </p>
            <p>
                With a foundation in Computer Science from Northern Virginia Community College, 
                I enjoy coding projects and data analysis relevant to the medical world.
            </p>

            
            
        </section>
        <!--Projects-->
        <section>
            <h1 id="projects">Projects</h1>

        
        <hr>

            <!--Offline Transcription-->

            <h2 class = 'projectTitle'>Offline Transcription</h2>
            <div class = 'centerButton'>
                <a class = 'projectButton' href="https://github.com/pkingGMU/OpenAi-Whisper-Interview-Transcription" target = '_blank'>Repo</a>
            </div>
            <h3>2024</h3>
            <ul class="skills">
                <li>Python</li>
                <li>AI</li>
                <li>pytorch</li>
                <li>Tensorflow</li>
                <li>Speech Recognition</li>
            </ul>
            <p>
                An intership I participated in during the summer of 2024 involved 
                interviewing subjects to further explore people's chronic pain
                experience. This was done under the OSCAR program at George Mason University. This research was a qualitative study that required
                transcription of hour long interviews. I proposed we create a transcription
                application that the team could use instead of painfully manually transcribing.
                The application would take in an audio file and output a text file of the transcription, but
                there were a few caveats. The application had to be offline, as the interviews contained 
                sensitive medical and personal data. The project me and a colleague created was an offline
                transcription model that could transcribe, diarrize, and remove personal information 
                all on a secure encrypted server.
            </p>

            <!--Insert img in images folder-->
            <div class = 'imgContainer'>
                <img src="img/Poster.png" alt="Offline Transcription Poster" class="projectImage" onclick="zoomImage(this)">
                <img src="img/transcription.png" alt="Transcription" class="projectImage" onclick="zoomImage(this)">
            </div>
            
            <hr>

            <h2 class = 'projectTitle'>TUG Test Data Analysis</h2>
            <div class = 'centerButton'>
                <a class = 'projectButton' href="https://github.com/pkingGMU/Tug_Test" target = '_blank'>Repo</a>
            </div>
            <h3>2024</h3>
            <ul class="skills">
                <li>MatLab</li>
                <li>Data Analysis</li>
                
            </ul>
            <p>
                Working as an Undergraduate Research Assistant at George Mason University's SMART Lab provided me with the opportunity to help PHD students with their abstracts and thesis work.
                One of the projects I majorly contributed to was a data analysis of the biomechanic 'TUG Test'. We wanted to see the difference in turning speed and acceloration between Dual
                and Single Task in the Tug Test. For this project we collected data from subjects using the wearable technology 'APDM' (Ambulatory Parkinson's Disease Monitor). Extracting and utilizing
                the accelorameter data that was produced proved quite difficult as it needed to be resampled and normalized to be usable. The custom matlab scripts I implemented were able to do
                this and provide the data needed for the research. After the Data had been cleaned I wrote the functions that allowed the researched to open their file explorer and choose the data they wanted
                to analyze. It then gave them a graph of the data and the ability to export the data to an excel file.

            </p>

            <!--Insert img in images folder-->
            <div class = 'imgContainer'>
                <img src="img/TugTestGraph.png" alt="Tug Test Image 1" class="projectImage" onclick="zoomImage(this)">
            </div>

            <hr>

            <!--Range of Motion-->

            <h2 class = 'projectTitle'>Range Of Motion</h2>
            <div class = 'centerButton'>
                <a class = 'projectButton' href="https://github.com/pkingGMU/Joint-Angles" target = '_blank'>Repo</a>
            </div>
            <h3>2024</h3>
            <ul class="skills">
                <li>Python</li>
                <li>AI</li>
                <li>GUI</li>
            </ul>
            <p>
                Working with multiple research teams at George Mason Univeristies
                SMART Lab and the Kinesiology Department, I have been able to interact with
                cutting edge technology and wearable devices. With a background in physical therapy,
                this inspired me to create my own project that could benefit both researches and physical
                therapists. I created a markerless motion capture system that could calculate an individual's Range 
                of Motion (ROM) after capturing two different frames using a webcam.
            </p>

            <div class = 'imgContainer'>
                <img src="img/ROMxls.png" alt="Offline Transcription Poster" id="img3" class="projectImage" onclick="zoomImage(this)">
                <img src="img/2024-08-21 10-13-13 (online-video-cutter.com).gif" id="img4" alt="ROM" class="projectImage" onclick="zoomImage(this)">
            </div>

            <hr>

            

            
            
        </section>
    </main>

    

</body>
</html>